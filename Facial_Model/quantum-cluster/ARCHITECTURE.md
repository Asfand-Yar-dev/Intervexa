# ğŸ“ Smart Mock Interview System - Project Structure

```
quantum-cluster/
â”‚
â”œâ”€â”€ ğŸ“‚ models/                          # Core AI Models
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â””â”€â”€ Facial_AI_Module.py            # Main facial expression analysis class
â”‚       â”œâ”€â”€ FacialExpressionModel      # Main class
â”‚       â”‚   â”œâ”€â”€ __init__()             # Initialize with model warmup
â”‚       â”‚   â”œâ”€â”€ analyze_frame()        # Analyze single frame
â”‚       â”‚   â”œâ”€â”€ reset_history()        # Reset emotion buffer
â”‚       â”‚   â””â”€â”€ get_statistics()       # Get session stats
â”‚       â””â”€â”€ Features:
â”‚           â”œâ”€â”€ âœ“ DeepFace integration
â”‚           â”œâ”€â”€ âœ“ Emotion stabilization (deque-based)
â”‚           â”œâ”€â”€ âœ“ Model preloading (dummy analysis)
â”‚           â””â”€â”€ âœ“ Robust error handling
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                           # Testing & Validation
â”‚   â””â”€â”€ test_gui.py                    # Webcam testing interface
â”‚       â”œâ”€â”€ EmotionDetectionGUI        # Main GUI class
â”‚       â”‚   â”œâ”€â”€ __init__()             # Setup camera & model
â”‚       â”‚   â”œâ”€â”€ run()                  # Main loop
â”‚       â”‚   â”œâ”€â”€ _init_camera()         # Windows-compatible camera init
â”‚       â”‚   â”œâ”€â”€ _draw_ui()             # Render bounding boxes & text
â”‚       â”‚   â””â”€â”€ _show_statistics()     # Display session stats
â”‚       â””â”€â”€ Features:
â”‚           â”œâ”€â”€ âœ“ Real-time visualization
â”‚           â”œâ”€â”€ âœ“ Frame skipping optimization
â”‚           â”œâ”€â”€ âœ“ CAP_DSHOW for Windows
â”‚           â”œâ”€â”€ âœ“ FPS monitoring
â”‚           â””â”€â”€ âœ“ Interactive controls (Q/R/S)
â”‚
â”œâ”€â”€ ğŸ“„ examples.py                      # Usage examples & tutorials
â”‚   â”œâ”€â”€ example_basic_usage()          # Single frame analysis
â”‚   â”œâ”€â”€ example_continuous_monitoring() # 10-sec monitoring
â”‚   â”œâ”€â”€ example_emotion_tracker()      # Stress detection
â”‚   â””â”€â”€ example_save_results()         # Save to JSON
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                 # Python dependencies
â”‚   â”œâ”€â”€ deepface==0.0.79
â”‚   â”œâ”€â”€ opencv-python==4.8.1.78
â”‚   â”œâ”€â”€ tensorflow==2.16.1
â”‚   â””â”€â”€ ... (other dependencies)
â”‚
â”œâ”€â”€ ğŸ“„ setup.ps1                        # Automated setup script (PowerShell)
â”‚
â””â”€â”€ ğŸ“„ README.md                        # Complete documentation

```

## ğŸ”‘ Key Components

### 1. **Facial_AI_Module.py** (Core AI Engine)
   - **Purpose:** Emotion detection and analysis
   - **Input:** OpenCV frame (numpy array)
   - **Output:** Dict with emotion, confidence, face coords
   - **Key Innovation:** Deque-based stabilization prevents jitter

### 2. **test_gui.py** (Real-time Testing Interface)
   - **Purpose:** Webcam-based testing with visual feedback
   - **Performance:** 25-30 FPS with frame skipping
   - **Platform:** Windows-optimized (CAP_DSHOW)
   - **UI:** Bounding boxes, confidence scores, FPS counter

### 3. **examples.py** (Developer Integration Guide)
   - **Purpose:** Show how to use the model in different scenarios
   - **Includes:** 4 complete example workflows
   - **Use Cases:** Single-shot, continuous, stress detection, data logging

## ğŸ¯ Emotion Detection Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Webcam Feed â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Capture   â”‚ (OpenCV)
â”‚ 640x480 @ 30fps â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Skipping  â”‚ (Every 5th frame)
â”‚ Optimize Perf   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeepFace Analysis   â”‚
â”‚ - Face Detection    â”‚
â”‚ - Emotion CNN       â”‚
â”‚ - 7 Emotion Classes â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stabilization       â”‚
â”‚ - Store in deque    â”‚
â”‚ - Get mode (5 last) â”‚
â”‚ - Return stable     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visualization   â”‚
â”‚ - Bounding box  â”‚
â”‚ - Emotion label â”‚
â”‚ - Confidence %  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© Class Relationships

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EmotionDetectionGUI        â”‚
â”‚  (test_gui.py)              â”‚
â”‚                             â”‚
â”‚  - camera: VideoCapture     â”‚
â”‚  - model: FacialExpression  â”‚â—„â”€â”€â”€â”€â”
â”‚  - fps: float               â”‚     â”‚
â”‚  - current_emotion: str     â”‚     â”‚ Uses
â”‚                             â”‚     â”‚
â”‚  + run()                    â”‚     â”‚
â”‚  + _init_camera()           â”‚     â”‚
â”‚  + _draw_ui()               â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                                    â”‚
                                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  FacialExpressionModel          â”‚ â”‚
â”‚  (Facial_AI_Module.py)          â”‚ â”‚
â”‚                                 â”‚ â”‚
â”‚  - emotion_history: deque       â”‚â”€â”˜
â”‚  - history_size: int            â”‚
â”‚  - frame_count: int             â”‚
â”‚                                 â”‚
â”‚  + analyze_frame(frame)         â”‚
â”‚  + reset_history()              â”‚
â”‚  + get_statistics()             â”‚
â”‚  - _warmup_model()              â”‚
â”‚  - _get_most_common_emotion()   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow

```
User's Face
    â†“
Webcam (640x480)
    â†“
OpenCV Frame (BGR numpy array)
    â†“
FacialExpressionModel.analyze_frame()
    â†“
DeepFace.analyze(actions=['emotion'])
    â†“
{
  'emotion': 'happy',
  'confidence': 87.5,
  'face_coordinates': {x, y, w, h},
  'all_emotions': {...}
}
    â†“
Deque Stabilization Buffer [happy, happy, neutral, happy, happy]
    â†“
Mode Calculation â†’ 'happy'
    â†“
GUI Visualization (green box + label)
    â†“
Display to User
```

## ğŸš€ Execution Flow

### Initial Setup
1. User runs `python tests/test_gui.py`
2. EmotionDetectionGUI.__init__() is called
3. FacialExpressionModel.__init__() loads DeepFace
4. Dummy analysis preloads model weights
5. Camera opens with CAP_DSHOW

### Main Loop
1. Capture frame from webcam
2. Increment frame counter
3. Check if frame_count % skip_frames == 0
4. If yes â†’ analyze_frame()
5. Update emotion history
6. Calculate stabilized emotion
7. Draw bounding box and label
8. Display frame
9. Check for user input (Q/R/S)
10. Repeat

### Cleanup
1. User presses 'Q'
2. Show statistics
3. Release camera
4. Destroy windows
5. Exit gracefully

## ğŸ“¦ Dependencies Tree

```
Your Application
    â”‚
    â”œâ”€â”€â”€ deepface (0.0.79)
    â”‚       â”œâ”€â”€â”€ tensorflow (2.16.1)
    â”‚       â”œâ”€â”€â”€ keras
    â”‚       â”œâ”€â”€â”€ opencv-python
    â”‚       â””â”€â”€â”€ numpy
    â”‚
    â”œâ”€â”€â”€ opencv-python (4.8.1.78)
    â”‚       â””â”€â”€â”€ numpy
    â”‚
    â””â”€â”€â”€ tf-keras (2.16.0)
            â””â”€â”€â”€ tensorflow
```

## ğŸ¨ UI Layout (test_gui.py)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Smart Mock Interview System - Emotion Detection    â”‚ â† Top Panel (semi-transparent)
â”‚  FPS: 28.5 | Emotion: Happy                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚                                                     â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚            â”‚                   â”‚                   â”‚
â”‚            â”‚ Happy (87.5%) â†â”€â”€â”€â”¼â”€â”€â”€ Green label    â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚            â”‚                   â”‚                   â”‚
â”‚            â”‚   [Face Region]   â”‚ â†â”€â”€â”€ Green box    â”‚
â”‚            â”‚                   â”‚                   â”‚
â”‚            â”‚                   â”‚                   â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                     â”‚
â”‚                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Press 'Q' to quit | 'R' to reset | 'S' for stats  â”‚ â† Bottom Panel
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Error Handling Strategy

```
Frame Analysis
    â”‚
    â”œâ”€ Try: DeepFace.analyze()
    â”‚   â”œâ”€ Success â†’ Extract emotions
    â”‚   â”‚   â”œâ”€ Face found â†’ Update history
    â”‚   â”‚   â””â”€ No face â†’ enforce_detection=False (no crash)
    â”‚   â”‚
    â”‚   â””â”€ Exception â†’ Catch & log
    â”‚       â”œâ”€ Set success = False
    â”‚       â”œâ”€ Store error message
    â”‚       â””â”€ Return gracefully (no crash)
    â”‚
    â””â”€ Return result dict (always)
```

---

**Last Updated:** January 21, 2026  
**Version:** 1.0.0  
**Status:** Production Ready âœ“
